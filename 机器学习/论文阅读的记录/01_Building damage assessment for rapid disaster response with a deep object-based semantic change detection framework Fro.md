# Building damage assessment for rapid disaster response with a deep object-based semantic change detection framework: From natural disasters to man-made disasters
## 1.解决灾害评估问题的关键是

在建筑物损伤评估中，**强的特征表示和语义一致性**是获得高准确率的关键

- 特征工程与表示学习
  - 特征学习：又叫表示学习(representation learning)或者表征学习，一般指模型自动从数据中抽取特征或者表示的方法，是**模型自动学习的过程**；
  - 特征工程:  主要指对于数据的人为处理提取，得到我们认为的适合后续模型使用的样式，是**人工提取的工程** （狭义的特征工程指的是“洗数据”：处理缺失值，特征选择，维度压缩等各种预处理手段，但从更广义的角度看，这些处理是为了使得数据有更好的表达以便后续应用）
- 语义一致性的概念表示地理对象相对于所用模型的描述质量。

## 2.现有解决方案的问题点

传统的基于对象的图像分析(OBIA)框架使用基于patch的卷积神经网络(CNN)可以保证语义的一致性，但特征表示较弱，而Siamese全卷积网络方法具有较强的特征表示能力，但语义不一致。

- 基于对象的图像分析（OBIA）分割是一个将相似像素分组为对象的过程。

  基于传统像素 为每个像素指定一个土地覆盖类别。所有像素的大小、形状都相同，没有任何相邻像素的概念。

  ![](https://raw.githubusercontent.com/bigshcool/myPic/main/202209211933050.png)

  OBIA分类使用物体的形状、大小和光谱特性对每一个物体进行分类

  ![](https://raw.githubusercontent.com/bigshcool/myPic/main/202209211935510.png)

  **综上所示，OBIA的两个基本原则上:**

  - 分解：将图像分解位表示陆基特征的对象。

  - 分类：OBIA分类使用物体的形状、大小和光谱特性对每一个物体进行分类

- Siamese全卷积网络方法

  ...**ToDo**...

### 3.提出的解决方法

在本文中，我们提出了一个基于深度对象的语义变化检测框架，称为ChangeOS，用于建筑物损伤评估。为了实现OBIA和深度学习的无缝集成，我们采用了深度对象定位网络来生成精确的建筑对象，取代了传统OBIA框架中常用的超像素分割。在此基础上，将深度目标定位网络和深度损伤分类网络集成为统一的语义变化检测网络，实现对建筑物的端到端损伤评估。这还提供了深度对象特征，可以在深度损伤分类网络之前提供对象，以实现更一致的语义特征表示。采用基于对象的后处理进一步保证了各个对象语义的一致性。

### 4. Introduction

​		（**前提:随着传感器空间分辨率的提高，现在可以获得高铁遥感图像，以精细表征每个建筑实例的空间细节，这使得评估实例级建筑损伤成为可能**）高空间分辨率(HSR)遥感图像可以准确地反映地球表面，并可以快速提供大面积观测数据，支持建筑损伤评估。当基于双时相高铁遥感图像时，建筑损伤评估可以被视为两个基本子任务的结合:**建筑定位和损伤分类**。

- 建筑定位，也被称为建筑提取，其目标是为灾前图像上的每个像素分配一个唯一的语义标签，以指示建筑面积。
- 损伤分类，根据灾前图像上的建筑物定位结果，为灾后图像上的每个建筑物实例分配一个唯一的损伤级别标签，以反映其损伤程度

#### 4.1 目前的主流方法

- Brunner等人(2010)联合使用HSR光学和SAR图像提取建筑实例，并通过地震灾害的几何参数估计评估实例级建筑损伤
- Tong et al.(2012)使用IKONOS图像，基于地震灾害的三维几何变化来检测每一个倒塌的建筑。
  - 步骤方法
    - 使用SAR或者光学采样
    - 针对不同的采样图像采用不同的特征提取方式
    - 将建筑损伤评估问题建模为事件前和事件后变化检测问题

**算法的问题处理的都是单一图像，手工计算过于繁琐**

- CNN

  卷积神经网络是一种分层特征表示学习方法，它允许我们使用数据驱动范式从原始图像数据中提取高级特征，并以端到端方式将这些特征应用到下游任务。**从网络结构的角度来看**，基于cnn的建筑物损伤评估方法大致可分为基于**级联网络的方法和基于暹罗网络**的方法。

  - 级联网络
    - 使用全卷积网络(FCN)进行建筑定位(**使用建筑定位模型预测灾难前图像上的像素级建筑位置**)
    - 使用基于补丁的CNN进行损伤分类(**应用损伤分类模型对灾后图像进行逐块损伤分类**)

  ```
  传统方法1:
  Gupta, R., Hosfelt, R., Sajeev, S., Patel, N., Goodman, B., Doshi, J., Heim, E., Choset, H., Gaston, M., 2019b. xbd: A Dataset for Assessing Building Damage From Satellite Imagery. arXiv:1911.09296 (arXiv preprint). 
  1.使用改进的UNet(FCN的变种)架构实现建筑定位
  2.并使用双分支ResNet-50(残差神经网络)实现损伤分类
  
  无论是UNet或者ResNet都是需要对建筑物识别，但是前者是基于像素级，后者是基于图像级，所以两个模型的知识无法共享，需要打补丁。
  ```

  

  ```
  传统方法2:
  Siamese-UNet:采用相同的网络结构，使用两个基于像素级的FCN模型(都采用了FCN模型，基于像素建模，解决了知识的无法通用性)。
  1.对灾前图像进行训练，进行建筑定位。
  2.获得的权重对灾前和灾后图像进行训练，进行损伤分类
  
  算法核心:使用两种相同的具有共享权重的UNet架构，从最后一个解码器块中提取灾前和灾后图像的密集特征映射。然后将这两个密集的特征图连接起来进行像素级损伤分类。(个人理解还是说由图像级去适应像素级，然后进行图像分类。)
  
  但算法引入了新的问题:无法保证语义的一致性。因为在级联模型下设计下，对于建筑受损分类是基于图像。例如：一个建筑物的受损等级标签应该只有一个，往往一个建筑物的受损面积将比整个建筑物小很多，而基于像素级别的学习过程将只能识别受损面积，但是无法确定一个受损建筑实例。
  ```

  

  ```
  传统方法3:
  基于补丁的CNNs集成OBIA
  主要采用超像素分割来生成对象，但对象是非语义的，几何形状不规则。然而，在建筑物损伤评估中，语义和规则几何形状的建筑物对象会发生语义不一致，导致这些传统的OBIA方法无法应用于建筑物损伤评估,这是因为目前的OBIA方法仅仅是在过程级与深度学习相结合，而没有特征级的交互。
  ```

  - 暹罗网络

#### 4.2 本文方法

​		为了保证OBIA与深度学习的无缝集成，我们采用了一个FCN来生成更精确的建筑对象，以取代超像素分割，这个FCN还负责像素级的建筑定位。此外，ChangeOS通过使用部分Siamese FCN架构，将建筑定位和损伤分类集成到一个统一的框架中，从而实现特征表示级别的交互。

​		数据集来源:https://www.digitalglobe.com/ecosystem/open-data

​		方法输入和输出如图。输入的是灾前和灾后双时图像。输出是一个表示建筑物位置的二进制掩码，和一个表示建筑物损坏程度的多类掩码。

![](https://raw.githubusercontent.com/bigshcool/myPic/main/202209251702947.png)

#### 4.2.1 损伤等级

| Damagelevel  | Description                                                  |
| ------------ | ------------------------------------------------------------ |
| Non-damage   | Undisturbed. No sign of water, structural or shingle damage or burn marks. |
| Minor damage | Building partially burnt, water surrounding structure, volcanic flow  nearby, roof elements missing, or visible cracks. |
| Major damage | Partial wall or roof collapse, encroaching volcanic flow or surrounded by water/mud. |
| Destroyed    | Scorched, completely collapsed, partially/completely covered with water/mud, or otherwise no longer present. |

#### 4.2.2 ChangeOS组成以及特点

![](https://raw.githubusercontent.com/bigshcool/myPic/main/202209251709701.png)

ChangeOS直接以双时图像为输入，输出实例级的建筑损伤评估结果，包括每个建筑的位置和损伤状态。部分编码器提取任务无关的深度特征，然后使用任务感知上下文编码器进一步提取任务感知上下文来增强深度特征。对于多任务预测，采用多任务解码器，实现多任务特征交互。

- 组成部件

  - partial Siamese encoder(部分孪生编码器)

    ​        部分孪生体编码器是一个FCN模型，用于为下游任务提取与任务无关的深度特征。对于双时光学图像，我们引入了一种权值共享机制来重用网络结构及其权值，以缓解过拟合问题。

    ​        这是由于灾前和灾后图像由相同的光学传感器采集，但处于不同的时间阶段，因此双时相图像属于相同的模态，具有相似的视觉模式。在这种情况下，两个独立的网络权重会产生巨大的冗余参数空间，阻碍网络训练。因此，共享权值可以显著降低参数空间的复杂性，缓解过拟合问题。

  - task-aware contextual encoder(上下文编码器)

    ​       对于不同的任务，需要从不同的范围捕获上下文信息。为此，我们提出了一个任务感知的上下文编码器，进一步提取任务感知的上下文信息，以获得任务感知和上下文增强的深层特征。任务感知上下文编码器由三个上样本块组成，对于建筑定位和损伤分类，网络架构相同，但权重不同。

    ​		引入了横向连接，将具有较长范围上下文的高级特征图和具有更细空间细节的低级特征图结合起来。

  - multi-task decoder(多任务译码器)

    ​		为了进一步进行基于对象的分类，我们通过连接组件标记算法(Wu等人，2005年)将建筑定位任务从语义分割改进为实例分割，该算法输出一组对象多边形，但可以通过像素级损失函数进行监督。多任务解码器以四种比例尺的特征图为输入输出二值概率图表示建筑物的位置，多类概率图表示每个像素的损伤分类概率。这个多任务解码器由两个相同的子网络组成。

  - object-based post-processing（基于对象的后处理器）

    ​		**多任务解码器得到的建筑物定位和损伤分类都是像素级的分类结果，像素级表示总是导致部分损伤识别**。意味着建筑对象的所有像素在语义上应该是一致的，即为一个整体对象。

  

