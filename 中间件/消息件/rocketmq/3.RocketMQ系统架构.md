# RocketMQ 系统架构

![img](https://github.com/apache/rocketmq/raw/master/docs/cn/image/rocketmq_architecture_1.png)

## 1.Producer生产者

消息的生产者，负责生产消息。Producer通过MQ进行负载的均衡模块选择相应的**Broker集群队列**进行消息的投递，投递的过程中支持快速失败并且低延迟。

```
例如: 业务系统生产的日志写入到MQ的过程中，就是消息的生产的过程.

再如，电商平台用户提交的秒杀请求写入到MQ过程，就是消息生产的过程。
```

RocketMQ中消息的生产都是以生产者组(Producer Group)的形式出现的。生产者组是同一类生产者的集合，这类Producer生产相同的Topic类型的消息。一个生产者组可以同时可以发送多个主题的消息。

## 2. Consumer

消息消费者，负责消费消息，一个消息消费者会从Broker服务器中获取消息，并对消息进行相关业务处理。

RocketMQ中的消息都是以消费组的形式出现的，消费者是一组同一类的消费者的集合，这类Consumer消费的是同一个Topic类型的消息。消费者使得在消息消费方面，实现负载均衡和容错的目标变得非常容易。

```
例如：Qos系统从MQ中读取日志，并对日志进行解析处理的过程就是消息消费的过程。
再如，电商平台的业务系统从MQ中读取秒杀请求，并对请求处理的过程就是消息消费的过程。
```

RocketMQ中的消息消费者都已消费者组(Consumer Group)的形式出现，消费者组是同一类消费者的集合，这类的Consumer消费的是同一个Topic类型的消息。消费者组使得在消息消费方面，实现负载均衡和容错的目标是非常容易的。

**负载均衡: 指的是队列的负载均衡而不是消息的负载均衡,将同一个Topic中不同的Queue平均分配的同一个Consumer Group的不同的Consumer。**

**容错: 一个Consumer挂了，该Consumer Group中的其他的Consumer可以接着消费原Consumer消息的Queue的目标非常容易。**

![image-20230512092904233](https://raw.githubusercontent.com/bigshcool/myPic/main/image-20230512092904233.png)

消费者组中的Consumer的数量应该小于等于订阅Topic的Queue数量，如果超过Queue数量，则多出的Consumer将不能消费消息。**注意这里强调的是在同一个组内，非同一个组内就算消费者多了是可以共同消费同一个Queue，如下**

![image-20230512093312805](https://raw.githubusercontent.com/bigshcool/myPic/main/image-20230512093312805.png)

不过，一个Topic类型的消息可以被多个消费者组同时消费

```
1. 消费者组只能消费一个Topic消息的，不能同时消费多个Topic消息
2. 一个消费者组中的消费者必须订阅完全相同的Topic
```

## 3. Name Server

NameServer是一个Broker与Topic路由的注册中心，支持Broker的动态注册和发现。

主要包括两个功能

- Broker管理:接受Broker集群的注册信息并且保存下来作为路由的信息的基本数据；提供心跳检测机制，检查Broker是否还存活。
- 路由信息管理:每个NameServer中都保存着Broker集群的整个路由信息和用于客户端查询的队列信息。Producer和Conumser通过NameServer可以获取整个Broker集群的路由信息，从而进行消息的投递和消费。

### 3.1 路由注册

NameServer通常也是以集群方式部署，不过，NameServer是无状态的话，即NameServer集群中的各种节点间无差异的，各节点相互不进行信息通信。那各节点中的数据是如何进行数据同步的呢？在Broker节点启动时，轮询NameServer列表中，与每个NameSearver节点建立长连接，发起注册请求。在NameServer内部维护者一个Broker列表，用来动态维护Broker的信息。

```
注意，这是与其他像zk，Eureka，nacos等注册中心不同的地方

这种nameServer无状态方式，有什么优缺点:

优点: NameServer集群搭建简单

缺点: 组建了NameServer集群，因为彼此之间不会进行数据通讯，所以扩容的时候直接搭建新的机器就可以了，每个NameServer不会有数据同步，所以Broker节点启动的时候需要轮询NameServer列表，就是说Broker就得挨个告诉每一个NameServer，一旦有新的NameServer加进来以后，broker节点是不知道这个新加的的NameServer。
```

Broker节点是为了证明自己还活着，为了维护和NameServer间的长连接，会将最新的信息以心跳包的方式上报给NameServer，每30s发送一次心跳。心跳包括BrokerId，Broker地址，Broker名称，Broker所属集群名称等。NameServer在接收到心跳后，会更新心跳时间戳，记录这个Broker的最新存活时间。

### 3.2 路由剔除

由于Broker关机，宕机或者网络抖动等原因，NameServer没有受到Broker的心跳，NameServer可能会将其从Broker列表中剔除。

NameServer中有一个定时任务，每隔10S就会扫描一次Broker表，查看每一个Broker的最新心跳时间戳，距离当前时间是否超过120s，如果超过120s就会判定Broker失效，然后将其从Broker列表中剔除。

```
扩展: 对于RocketMQ日常运维工作，如Broker升级，需要停掉Broker工作。OP需要怎么做。

OP需要将Broker的读写权限禁掉。一旦client(consumer或者produce)向broker发送请求，都会受到broker的NO_PERMISSION相应，然后client会对他进行其他的Broker重试，此时的写权限应该还不会禁用，如果内部有消息的话，依然要消费者消费。

当OP观察到这个Broker没有流量后，再关闭它，实现Broker从NameServer移除。
```

### 3.3 路由发现

RocketMQ的路由发现采用的是Pull模型，当Topic路由信息出现变化时，NameServer不会主动推送到客户端，而是客户端定时拉取最新的路由。默认客户端每30s会拉取一次最新的路由。

```
扩展:
1.)Push模型:推送模型，其实时性较好，是一个发布订阅模型，需要维护一个长连接。而长连接的维护是需要资源成本的，该模型始适用于该场景。
	- 实时性要求较高
	- client数量不多，Server变化比较频繁
2.)Pull模型:拉取模型，存在的问题是，实时性较差。
3.)Long Polling模型:长轮询模型。其是对Push和Pull模型的整合，充分利用了这两种模型的优势，屏蔽他们的劣势。
```

### 3.4 客户端NameServer选择策略

**这里的客户端指的是Producer和Consumer**

客户端在配置时必须要写上NameServer集群地址，那么客户端连接到底是哪个NameServer节点呢?客户端首先会产生一个随机数，然后再与NameServer节点数量取模，此时得到的就是所要连接的节点索引，然后就会进行连接。如果连接失败，则会采用round-robin策略，逐个尝试去链接其他节点。

首先采用的是**随机策略**进行的选择，失败后采用的是**轮询策略**。

```
扩展: Zookeeper Client是如何选择Zookeepr Server的？
     经过两次Shuffle，然后选择第一台Zookeeper Server。
     详细的说就是，将配置文件中的ZK server地址进行第一次的shuffle，然后随机选择一个，这个选择出来的一般都是一个hostname，然后获取到hostname所对应的所有IP，再对这些IP进行第二次的shuffle，从shuffle过的结果中取第一个server进行封装。
```



## 4. Broker

- 功能介绍

  Broker充当着消息中转角色，负责存储消息，转发消息。Broker再RocketMQ系统中负责接受并存储从生产者发送来的消息，同时为消费者的拉取请求做准备。Broker同时也存储着相关的元数据，包括消费者组消费进度偏移offset，主题，队列等。

  ![image-20230512105805138](https://raw.githubusercontent.com/bigshcool/myPic/main/image-20230512105805138.png)

  - Remoting Module:整个Broker实体，负责处理来自clients的请求。而这个Broker实体则有下面的模块构成。
    - clients Manager:客户端管理器。负责接受,解析客户端(Producer/Consumer)请求，管理客户端。例如:维护Consumer的Topic订阅信息。
    - Store Service：存储服务。提供方便简单的API接口，**处理消息存储到物理硬盘和消息查询的功能**
    - HA Service:高可用服务，提供Master Broker和Slave Broker之间的数据同步功能
    - Index Service:索引服务，根据特定的Message Key，对投递到Broker消息进行索引服务，同时也提供了根据Message Key对消息进行快速查询的功能。

- 集群部署

为了增强Broker性能与吞吐量，Broker一般都是以集群形式出现的。各个集群节点可能存放着相同的Topic的不同Queue。不过这里有个问题，如果有Broker节点宕机，如果保证数据不丢失呢？其解决办法是，将每个Broker集群节点继续横向扩展，即将Broker再建一个HA集群，解决单点问题。

Broker节点集群是一个主从集群，即集群中具有Master与slave两个角色。Master负责处理读写操作请求，而Slave对Master中的数据进行备份。当Master挂掉以后，Slave则自动切换为Master去工作，所以这个Broker集群是主备关系。一个Master可以包含多个slave，但是一个Slave只能隶属于一个Master。Master与Slave的对应关系是通过指定相同的BrokerName，通过不同的BrokerId爱确定。BrokerId为0表示Master，非0表示Slave。每个Broker和NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有的NameServer。

## 5.工作流程

1. 启动NameServer，NameServer启动开启监听端口，等待Broker，Producer，Consume连接
2. 启动Broker时，Broker会与所有的NameServer建立并且保持长连接，然后每30秒向NameServer定时发送心跳包
3. 发送消息前，可以先创建Topic，创建Topic时需要指定该Topic要存储到哪些Broker上，当然，在创建Topic上也会将Topic与Broker的关系写入到NameServer中，不过这一步是可选的，也可以在发送消息时自动创建Topic，
4. Producer发送消息，启动时先和NameServer集群中的其中一台建立长连接，并从NameServer中获取到了路由信息，即当前发送的Topic消息的Queue和Broker地址的映射关系。然后根据算法策略从队选择一个Queue，与队列所在的Broker建立长连接从而向Broker发消息。当然，在获取到路由信息后，Producer会首先将路由信息缓存到本地，再每30s从NameServer更新一次路由信息。**注意负载均衡是按照Queue进行负载均衡的，而不是按照Broker数量进行负载均衡的**
5. Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取其订阅的Topic的路由信息，然后根据算法策略从路由信息中获取到所有需要消费Queue，然后直接跟Broker建立长连接，开始消费其中的消息，Consumer再获取到路由后，同样也会30s以后从NameServer更新一次路由信息。不过不同于Producer的是，Consumer还会向Broker发送心跳，以确保Broker的存活状态

- Topic创建

  Topic的手动创建由两种模式:

  - 集群模式：该模式下创建的Topic在集群中，所有的Broker中的Queue是相同的
  - Broker模式: 该模式创建下的Topic在该集群中，每个Broker可以不同。

  自动创建的时候采取的是Broker模式，会给每个Broker创建四个Queue

- 读/写队列

  从物理上来讲，读/写队列是同一个队列。所以，不存在读/写队列数据同步问题。读/系欸队列是从逻辑上进行区分的。一般情况下，读/写队列的数量是相同的。

  但是也有可能会不同，假如创建Topic时的写队列数量为4，读队列数量为8，此时系统会创建8个Queue，分别是0 1 2 3 4 5 6 7。Producer会将消息写入到这4个队列，但是Consumer指挥消费0 - 7队列中的信息， 但是4 5 6 7中是没有消息的。此时假设Consumer Group中包含两个Consuer，Consumer 1消费 0 1 2 3.而Consumer2 消费消息 4 5 6 7.但是实际情况是，Consumer2 是没有消息可以消费的。

  **也就是读写队列不相同的时候，总是有问题的，这样设计的目的是方便的Topic的Queue的缩容，假设从原来的创建的Topic中包含16Queue，如何能够使其Queue缩容为8个，还不会丢失消息？可以动态修改写队列的数量为8。此时新的消息只能写到前8个新的队列中，而消费队列还是16个队列中的数据，当发现后八个队列的中消息消费完毕后，可以在将读队列数量动态设置为8，整个缩容的过程中没有丢失任何信息。**

  

  